{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90272c-152c-49cc-9855-8d474f61d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Pipeline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "\n",
    "review_fp = \"/yelp_academic_dataset_review.json\"\n",
    "business_fp = \"/yelp_academic_dataset_business.json\"\n",
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1. ESG Keyword Filtering\n",
    "# 1.1 ESG Keywords\n",
    "ESG_KEYWORDS = [\n",
    "    # Environmental\n",
    "    \"sustainable\", \"organic\", \"eco-friendly\", \"recyclable\", \"renewable\",\n",
    "    # Social\n",
    "    \"fair trade\", \"community\", \"local sourcing\", \"ethical\",\n",
    "    # Governance\n",
    "    \"transparency\", \"responsible\", \"ESG\"\n",
    "]\n",
    "\n",
    "# 1.2 Load & Filter Data\n",
    "def load_and_filter_reviews(review_fp, business_fp, keywords):\n",
    "    print(\"Loading business data...\")\n",
    "    business_df = pd.read_json(business_fp, lines=True)\n",
    "    print(\"Loading review data...\")\n",
    "    review_df = pd.read_json(review_fp, lines=True)\n",
    "\n",
    "    # Merge on business_id\n",
    "    merged_df = review_df.merge(business_df[[\"business_id\", \"name\", \"categories\"]], on=\"business_id\", how=\"left\")\n",
    "\n",
    "    # Filter by ESG keywords\n",
    "    pattern = \"|\".join([re.escape(k) for k in keywords])\n",
    "    mask = merged_df[\"text\"].str.contains(pattern, case=False, na=False)\n",
    "    filtered_df = merged_df[mask].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Total reviews after ESG filter: {len(filtered_df)}\")\n",
    "    return filtered_df\n",
    "\n",
    "df = load_and_filter_reviews(review_fp, business_fp, ESG_KEYWORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b6c86-a81f-475d-9ad5-ef6a540ad04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. LDA Topic Modeling\n",
    "# 3.1 Preprocess for LDA\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return [token.lemma_ for token in doc if token.is_alpha and token.text not in stop_words]\n",
    "\n",
    "df[\"tokens\"] = [preprocess(t) for t in tqdm(df[\"text\"], desc=\"Preprocessing\")]\n",
    "\n",
    "# 3.2 LDA Topic Modeling with Coherence Selection\n",
    "dictionary = corpora.Dictionary(df[\"tokens\"])\n",
    "corpus = [dictionary.doc2bow(text) for text in df[\"tokens\"]]\n",
    "\n",
    "def find_best_lda(dictionary, corpus, texts, start=3, limit=10):\n",
    "    best_score, best_model, best_k = -1, None, None\n",
    "    for k in range(start, limit+1):\n",
    "        model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k, passes=5, random_state=42)\n",
    "        coherence = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence=\"c_v\").get_coherence()\n",
    "        print(f\"Topics: {k}, Coherence: {coherence:.4f}\")\n",
    "        if coherence > best_score:\n",
    "            best_score, best_model, best_k = coherence, model, k\n",
    "    return best_model, best_k, best_score\n",
    "\n",
    "lda_model, best_k, best_score = find_best_lda(dictionary, corpus, df[\"tokens\"])\n",
    "print(f\"Best topic count: {best_k} with coherence {best_score:.4f}\")\n",
    "\n",
    "# 3.3 Extract topic keywords and probabilities\n",
    "def get_topic_keywords(lda_model, dictionary, num_words=10):\n",
    "    topics = []\n",
    "    for topic_id in range(best_k):\n",
    "        topic_terms = lda_model.show_topic(topic_id, num_words)\n",
    "        topic_words = [word for word, _ in topic_terms]\n",
    "        topic_probs = [prob for _, prob in topic_terms]\n",
    "        topics.append({\"topic_id\": topic_id, \"words\": \", \".join(topic_words), \"probabilities\": \", \".join(f\"{p:.4f}\" for p in topic_probs)})\n",
    "    return topics\n",
    "\n",
    "topics_data = get_topic_keywords(lda_model, dictionary)\n",
    "topics_df = pd.DataFrame(topics_data)\n",
    "topics_df.to_csv(os.path.join(output_dir, \"topics.csv\"), index=False)\n",
    "print(f\" Topic keywords saved to {os.path.join(output_dir, 'topics.csv')}\")\n",
    "\n",
    "# 3.4 Add topic distributions to reviews for ABM\n",
    "def get_topic_distributions(lda_model, corpus, df):\n",
    "    topic_distributions = []\n",
    "    for bow in corpus:\n",
    "        topic_dist = lda_model.get_document_topics(bow, minimum_probability=0.0)\n",
    "        dist = [0.0] * best_k\n",
    "        for topic_id, prob in topic_dist:\n",
    "            dist[topic_id] = prob\n",
    "        topic_distributions.append(dist)\n",
    "    df[\"topic_distribution\"] = topic_distributions\n",
    "    return df\n",
    "\n",
    "df = get_topic_distributions(lda_model, corpus, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a4b7e67-24ec-491c-b860-26d65b40ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    review_id                 user_id             business_id  \\\n",
      "0      -7LkjSPzfVgnVpuVuRuOow  uAu772KpSkb-tPFgZmU-lA  2GYg3liJ9-m6Z67L_4_BRQ   \n",
      "1      r-PjI5sBvNoBekk5mURNww  uzy_KYIZx65cp7Yh8_seeQ  ZuM1vcZ_ObCjCCGweYzItg   \n",
      "2      hVs0KrkaRNaxmH2GQm2qLA  jcJGCNrEgPHsl7zkvumq2Q  QUEWdnmVCv2Ri8xJATTrIQ   \n",
      "3      bVgpM_sA9AMAlL2R5TPNAQ  8DSuxkm7SyX9fgQTw2tuaw  dz_aIFbATP2PLWQSOBnMfw   \n",
      "4      -RsFYcZz0HeSrAhu5xDWBg  -cb2SLDoCysQFxbDDf_0pg  Q1HHAb4FzrzfnnrRyA8fgg   \n",
      "...                       ...                     ...                     ...   \n",
      "78111  zWVJHU8L9txRPDlSMnHsYw  HuB6-5n480bnhtV6SHGUgQ  3LWPWhqWaLSDq6dktuB-jA   \n",
      "78112  R4dfSB633wUohJn9eq2fLQ  81QjvIwJK5JZZT6Ady0x3w  7KkgY_GrKT3Pal_6NN46yQ   \n",
      "78113  jxvrLD0XmCWFBNIrO17CRw  4bP86EzvAa0sfaxrYW5_BA  KQx5ZIETVo7_KBm0ovLfSw   \n",
      "78114  m_WyTXe6z6FlAzG7qjebEA  uw9cwb4qvH0EKvUh-X_W-w  necj933-7IiKCyMGj6ZWGQ   \n",
      "78115  kZiKvXxK7o5i7fa32u5Jgw  6jjHo9Lilv3kTy87pm2ycw  pQAQwhBlSQdG1HuuLuCqXw   \n",
      "\n",
      "       stars  useful  funny  cool  \\\n",
      "0          5       7      0     3   \n",
      "1          5      15      0     2   \n",
      "2          4       1      0     0   \n",
      "3          1       1      0     0   \n",
      "4          2       0      0     0   \n",
      "...      ...     ...    ...   ...   \n",
      "78111      4       1      0     1   \n",
      "78112      1       2      0     0   \n",
      "78113      5       0      0     0   \n",
      "78114      5       8      0     2   \n",
      "78115      5      46     17    45   \n",
      "\n",
      "                                                    text                date  \\\n",
      "0      I LOVE Weaver's Way and really disagree with s... 2008-12-03 04:13:43   \n",
      "1      I took the beginning class there, and I loved ... 2013-10-24 16:40:47   \n",
      "2      Came here after my husband bought home their l... 2016-06-11 22:14:35   \n",
      "3      Pretty slow service and the waitresses aren't ... 2017-05-13 16:53:19   \n",
      "4      My sister-in-law and I visited this restaurant... 2015-08-30 15:35:41   \n",
      "...                                                  ...                 ...   \n",
      "78111  This is always one of the best festival in Edm... 2013-08-07 03:58:12   \n",
      "78112  Having your reps go DOOR TO DOOR during a pand... 2020-11-30 21:56:46   \n",
      "78113  I cannot begin to say how happy I am that Spro... 2021-11-13 01:24:38   \n",
      "78114  We all need to splurge a little sometimes.  To... 2016-03-09 16:59:45   \n",
      "78115  Just $5 every SUNDAY in October! Do it!\\n\\nOh,... 2020-10-11 00:09:30   \n",
      "\n",
      "                             name  \\\n",
      "0               Weavers Way Co-Op   \n",
      "1                     Green Locus   \n",
      "2          Chicken and Watermelon   \n",
      "3       Maggie Mae's Sunrise Cafe   \n",
      "4        Cheeseburger in Paradise   \n",
      "...                           ...   \n",
      "78111  Edmonton Heritage Festival   \n",
      "78112               DaBella- Reno   \n",
      "78113      Sprouts Farmers Market   \n",
      "78114     Gangster Vegan Organics   \n",
      "78115              Imagine Museum   \n",
      "\n",
      "                                              categories  \\\n",
      "0      Pets, Cheese Shops, Health Markets, Grocery, F...   \n",
      "1      Gyms, Fitness & Instruction, Active Life, Yoga...   \n",
      "2                             Chicken Wings, Restaurants   \n",
      "3                        Restaurants, Breakfast & Brunch   \n",
      "4      Restaurants, Burgers, Bars, American (Traditio...   \n",
      "...                                                  ...   \n",
      "78111  Specialty Food, Food, Performing Arts, Festiva...   \n",
      "78112  Home Services, Roofing, Siding, Windows Instal...   \n",
      "78113  Organic Stores, Health Markets, Farmers Market...   \n",
      "78114  Juice Bars & Smoothies, Fruits & Veggies, Vege...   \n",
      "78115  Art Museums, Arts & Entertainment, Art Galleri...   \n",
      "\n",
      "                                                  tokens  \\\n",
      "0      [love, weaver, way, really, disagree, content,...   \n",
      "1      [take, beginning, class, love, perfectly, pace...   \n",
      "2      [come, husband, buy, home, lemon, pepper, wing...   \n",
      "3      [pretty, slow, service, waitress, kind, guess,...   \n",
      "4      [sister, law, visit, restaurant, mid, afternoo...   \n",
      "...                                                  ...   \n",
      "78111  [always, one, good, festival, edmonton, great,...   \n",
      "78112  [rep, go, door, door, pandemic, infuriate, nev...   \n",
      "78113  [begin, say, happy, sprout, finally, make, nor...   \n",
      "78114  [need, splurge, little, sometimes, steak, lobs...   \n",
      "78115  [every, sunday, october, oh, gasp, step, glass...   \n",
      "\n",
      "                                      topic_distribution  \n",
      "0      [0.08604245, 0.0007441175, 0.0007441482, 0.010...  \n",
      "1      [0.0033351725, 0.003335949, 0.10524713, 0.0033...  \n",
      "2      [0.0018207735, 0.072484896, 0.001820916, 0.081...  \n",
      "3      [0.0017252923, 0.12456746, 0.06602018, 0.00172...  \n",
      "4      [0.00093658443, 0.31016192, 0.00093643356, 0.0...  \n",
      "...                                                  ...  \n",
      "78111  [0.00084835367, 0.00084831554, 0.00084834464, ...  \n",
      "78112  [0.33506113, 0.006252654, 0.0062537757, 0.0062...  \n",
      "78113  [0.029984832, 0.0011497664, 0.0011498267, 0.00...  \n",
      "78114  [0.0007795455, 0.045295663, 0.00077952666, 0.1...  \n",
      "78115  [0.0005003074, 0.00050026906, 0.0005002465, 0....  \n",
      "\n",
      "[78116 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ad894-bf82-4137-9606-04dc353def49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. BERT Sentiment Analysis\n",
    "sentiment_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"/bert-base-multilingual-uncased-sentiment\",\n",
    ")\n",
    "# Process sentiment and map to 1-5 scale\n",
    "def map_sentiment(score):\n",
    "    # Convert BERT's [-1, 1] to [1, 5]\n",
    "    return (2 * (score) + 3)\n",
    "\n",
    "df[\"sentiment\"] = [map_sentiment(sentiment_model(t[:512])[0][\"score\"]) for t in tqdm(df[\"text\"], desc=\"BERT Sentiment\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a5fa6-e588-427f-a1bd-4c9ddaec378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs & model params\n",
    "df.to_csv(os.path.join(output_dir, \"esg_reviews_processed.csv\"), index=False)\n",
    "\n",
    "# Save sentiment results with topic_distribution\n",
    "sentiment_output = df[[\"review_id\", \"business_id\", \"text\", \"sentiment\", \"tokens\", \"topic_distribution\"]]\n",
    "sentiment_output.to_csv(os.path.join(output_dir, \"sentiment_results.csv\"), index=False)\n",
    "print(f\" Sentiment results saved to {os.path.join(output_dir, 'sentiment_results.csv')}\")\n",
    "\n",
    "# Convert tuple keys to \"word1,word2\" strings for JSON\n",
    "coocc_str_keys = {\",\".join(pair): count for pair, count in coocc}\n",
    "\n",
    "model_params = {\n",
    "    \"best_topic_count\": best_k,\n",
    "    \"coherence_score\": best_score,\n",
    "    \"esg_keywords\": ESG_KEYWORDS,\n",
    "    \"keyword_cooccurrence\": coocc_str_keys\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, \"model_params.json\"), \"w\") as f:\n",
    "    json.dump(model_params, f, indent=4)\n",
    "\n",
    "print(\" NLP pipeline completed. Outputs saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c0325ff-0349-4f5c-9fbb-50f33aa898d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    review_id                 user_id             business_id  \\\n",
      "0      -7LkjSPzfVgnVpuVuRuOow  uAu772KpSkb-tPFgZmU-lA  2GYg3liJ9-m6Z67L_4_BRQ   \n",
      "1      r-PjI5sBvNoBekk5mURNww  uzy_KYIZx65cp7Yh8_seeQ  ZuM1vcZ_ObCjCCGweYzItg   \n",
      "2      hVs0KrkaRNaxmH2GQm2qLA  jcJGCNrEgPHsl7zkvumq2Q  QUEWdnmVCv2Ri8xJATTrIQ   \n",
      "3      bVgpM_sA9AMAlL2R5TPNAQ  8DSuxkm7SyX9fgQTw2tuaw  dz_aIFbATP2PLWQSOBnMfw   \n",
      "4      -RsFYcZz0HeSrAhu5xDWBg  -cb2SLDoCysQFxbDDf_0pg  Q1HHAb4FzrzfnnrRyA8fgg   \n",
      "...                       ...                     ...                     ...   \n",
      "78111  zWVJHU8L9txRPDlSMnHsYw  HuB6-5n480bnhtV6SHGUgQ  3LWPWhqWaLSDq6dktuB-jA   \n",
      "78112  R4dfSB633wUohJn9eq2fLQ  81QjvIwJK5JZZT6Ady0x3w  7KkgY_GrKT3Pal_6NN46yQ   \n",
      "78113  jxvrLD0XmCWFBNIrO17CRw  4bP86EzvAa0sfaxrYW5_BA  KQx5ZIETVo7_KBm0ovLfSw   \n",
      "78114  m_WyTXe6z6FlAzG7qjebEA  uw9cwb4qvH0EKvUh-X_W-w  necj933-7IiKCyMGj6ZWGQ   \n",
      "78115  kZiKvXxK7o5i7fa32u5Jgw  6jjHo9Lilv3kTy87pm2ycw  pQAQwhBlSQdG1HuuLuCqXw   \n",
      "\n",
      "       stars  useful  funny  cool  \\\n",
      "0          5       7      0     3   \n",
      "1          5      15      0     2   \n",
      "2          4       1      0     0   \n",
      "3          1       1      0     0   \n",
      "4          2       0      0     0   \n",
      "...      ...     ...    ...   ...   \n",
      "78111      4       1      0     1   \n",
      "78112      1       2      0     0   \n",
      "78113      5       0      0     0   \n",
      "78114      5       8      0     2   \n",
      "78115      5      46     17    45   \n",
      "\n",
      "                                                    text                date  \\\n",
      "0      I LOVE Weaver's Way and really disagree with s... 2008-12-03 04:13:43   \n",
      "1      I took the beginning class there, and I loved ... 2013-10-24 16:40:47   \n",
      "2      Came here after my husband bought home their l... 2016-06-11 22:14:35   \n",
      "3      Pretty slow service and the waitresses aren't ... 2017-05-13 16:53:19   \n",
      "4      My sister-in-law and I visited this restaurant... 2015-08-30 15:35:41   \n",
      "...                                                  ...                 ...   \n",
      "78111  This is always one of the best festival in Edm... 2013-08-07 03:58:12   \n",
      "78112  Having your reps go DOOR TO DOOR during a pand... 2020-11-30 21:56:46   \n",
      "78113  I cannot begin to say how happy I am that Spro... 2021-11-13 01:24:38   \n",
      "78114  We all need to splurge a little sometimes.  To... 2016-03-09 16:59:45   \n",
      "78115  Just $5 every SUNDAY in October! Do it!\\n\\nOh,... 2020-10-11 00:09:30   \n",
      "\n",
      "                             name  \\\n",
      "0               Weavers Way Co-Op   \n",
      "1                     Green Locus   \n",
      "2          Chicken and Watermelon   \n",
      "3       Maggie Mae's Sunrise Cafe   \n",
      "4        Cheeseburger in Paradise   \n",
      "...                           ...   \n",
      "78111  Edmonton Heritage Festival   \n",
      "78112               DaBella- Reno   \n",
      "78113      Sprouts Farmers Market   \n",
      "78114     Gangster Vegan Organics   \n",
      "78115              Imagine Museum   \n",
      "\n",
      "                                              categories  \\\n",
      "0      Pets, Cheese Shops, Health Markets, Grocery, F...   \n",
      "1      Gyms, Fitness & Instruction, Active Life, Yoga...   \n",
      "2                             Chicken Wings, Restaurants   \n",
      "3                        Restaurants, Breakfast & Brunch   \n",
      "4      Restaurants, Burgers, Bars, American (Traditio...   \n",
      "...                                                  ...   \n",
      "78111  Specialty Food, Food, Performing Arts, Festiva...   \n",
      "78112  Home Services, Roofing, Siding, Windows Instal...   \n",
      "78113  Organic Stores, Health Markets, Farmers Market...   \n",
      "78114  Juice Bars & Smoothies, Fruits & Veggies, Vege...   \n",
      "78115  Art Museums, Arts & Entertainment, Art Galleri...   \n",
      "\n",
      "                                                  tokens  \\\n",
      "0      [love, weaver, way, really, disagree, content,...   \n",
      "1      [take, beginning, class, love, perfectly, pace...   \n",
      "2      [come, husband, buy, home, lemon, pepper, wing...   \n",
      "3      [pretty, slow, service, waitress, kind, guess,...   \n",
      "4      [sister, law, visit, restaurant, mid, afternoo...   \n",
      "...                                                  ...   \n",
      "78111  [always, one, good, festival, edmonton, great,...   \n",
      "78112  [rep, go, door, door, pandemic, infuriate, nev...   \n",
      "78113  [begin, say, happy, sprout, finally, make, nor...   \n",
      "78114  [need, splurge, little, sometimes, steak, lobs...   \n",
      "78115  [every, sunday, october, oh, gasp, step, glass...   \n",
      "\n",
      "                                      topic_distribution  sentiment  \n",
      "0      [0.08604245, 0.0007441175, 0.0007441482, 0.010...   3.857883  \n",
      "1      [0.0033351725, 0.003335949, 0.10524713, 0.0033...   4.234715  \n",
      "2      [0.0018207735, 0.072484896, 0.001820916, 0.081...   4.222333  \n",
      "3      [0.0017252923, 0.12456746, 0.06602018, 0.00172...   3.970430  \n",
      "4      [0.00093658443, 0.31016192, 0.00093643356, 0.0...   3.591356  \n",
      "...                                                  ...        ...  \n",
      "78111  [0.00084835367, 0.00084831554, 0.00084834464, ...   4.100261  \n",
      "78112  [0.33506113, 0.006252654, 0.0062537757, 0.0062...   4.500296  \n",
      "78113  [0.029984832, 0.0011497664, 0.0011498267, 0.00...   4.841977  \n",
      "78114  [0.0007795455, 0.045295663, 0.00077952666, 0.1...   4.054982  \n",
      "78115  [0.0005003074, 0.00050026906, 0.0005002465, 0....   4.870235  \n",
      "\n",
      "[78116 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a9936-c2ad-4fcc-8798-a670039964de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate topic prevalence\n",
    "topic_counts = [0] * best_k\n",
    "for dist in df[\"topic_distribution\"]:\n",
    "    max_topic = max(range(len(dist)), key=lambda i: dist[i])\n",
    "    topic_counts[max_topic] += 1\n",
    "prevalence_df = pd.DataFrame({\n",
    "    \"topic_id\": range(best_k),\n",
    "    \"count\": topic_counts,\n",
    "    \"proportion\": [count / len(df) for count in topic_counts]\n",
    "})\n",
    "prevalence_df.to_csv(os.path.join(output_dir, \"topic_prevalence.csv\"), index=False)\n",
    "print(f\" Topic prevalence saved to {os.path.join(output_dir, 'topic_prevalence.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57047054-05b8-4761-aedd-2afce9adc98d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
