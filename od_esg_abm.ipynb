{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09363d92-7993-41e3-8be9-e3ceab09a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model parameters: 10 topics, coherence=0.4635\n",
      "--- Running global baseline simulation ---\n",
      "--- Running all simulation scenarios ---\n",
      "Running Scenario 1 (Baseline)...\n",
      "Results saved to ./output/abm_results_1.csv\n",
      "Running Scenario 2 (Stagnation)...\n",
      "Results saved to ./output/abm_results_2.csv\n",
      "Running Scenario 3 (Acceleration)...\n",
      "Results saved to ./output/abm_results_3.csv\n",
      "\n",
      "--- Generating plots ---\n",
      "Generated all plots and results.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from mesa import Agent, Model\n",
    "from mesa.space import NetworkGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa.time import SimultaneousActivation\n",
    "\n",
    "# ===== Load NLP parameters =====\n",
    "input_dir = \"./output\"\n",
    "if not os.path.exists(input_dir):\n",
    "    os.makedirs(input_dir)\n",
    "    print(f\"Created directory: {input_dir}\")\n",
    "    dummy_params = {\n",
    "        \"best_topic_count\": 10, \"coherence_score\": 0.5,\n",
    "        \"esg_keywords\": [], \"keyword_cooccurrence\": {}\n",
    "    }\n",
    "    with open(os.path.join(input_dir, \"model_params.json\"), \"w\") as f:\n",
    "        json.dump(dummy_params, f)\n",
    "    \n",
    "    dummy_sentiment_df = pd.DataFrame({\n",
    "        \"sentiment\": [random.uniform(4.0, 4.8) for _ in range(100)],\n",
    "        \"topic_distribution\": [[random.random() for _ in range(10)] for _ in range(100)]\n",
    "    })\n",
    "    dummy_sentiment_df.to_csv(os.path.join(input_dir, \"sentiment_results.csv\"), index=False)\n",
    "    print(\"Created dummy NLP output files for demonstration.\")\n",
    "\n",
    "with open(os.path.join(input_dir, \"model_params.json\"), \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "BEST_TOPIC_COUNT = params[\"best_topic_count\"]\n",
    "COHERENCE_SCORE = params[\"coherence_score\"]\n",
    "ESG_KEYWORDS = params[\"esg_keywords\"]\n",
    "KEYWORD_COOC = params[\"keyword_cooccurrence\"]\n",
    "print(f\"Loaded model parameters: {BEST_TOPIC_COUNT} topics, coherence={COHERENCE_SCORE:.4f}\")\n",
    "\n",
    "# Load sentiment and topic data from NLP output\n",
    "sentiment_df = pd.read_csv(os.path.join(input_dir, \"sentiment_results.csv\"))\n",
    "sentiment_values = sentiment_df[\"sentiment\"].tolist()\n",
    "topic_vectors = sentiment_df[\"topic_distribution\"].apply(lambda x: json.loads(x) if isinstance(x, str) else x).tolist()\n",
    "\n",
    "# ===== ABM Agent and Model Classes =====\n",
    "class ReviewerAgent(Agent):\n",
    "    def __init__(self, unique_id, model, initial_sentiment, topic_vector):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.sentiment = initial_sentiment\n",
    "        self.topic_vector = topic_vector\n",
    "        self.intervened = False  # Track intervention status\n",
    "\n",
    "    def step(self):\n",
    "        neighbor_agents = self.model.grid.get_neighbors(self.pos, include_center=False)\n",
    "        if not neighbor_agents: return\n",
    "        \n",
    "        confidence_threshold = self.model.confidence_threshold\n",
    "        relevant_neighbors = [a for a in neighbor_agents if abs(a.sentiment - self.sentiment) <= confidence_threshold]\n",
    "        if not relevant_neighbors: return\n",
    "        \n",
    "        avg_neighbor_sentiment = np.mean([a.sentiment for a in relevant_neighbors])\n",
    "        self.sentiment += self.model.influence_strength * (avg_neighbor_sentiment - self.sentiment)\n",
    "        \n",
    "        esg_weights = [1 / BEST_TOPIC_COUNT] * BEST_TOPIC_COUNT\n",
    "        \n",
    "        neighbor_topic_vectors = [a.topic_vector for a in relevant_neighbors]\n",
    "        if neighbor_topic_vectors:\n",
    "            avg_neighbor_topics = np.mean(neighbor_topic_vectors, axis=0)\n",
    "            self.topic_vector = [\n",
    "                (1 - self.model.influence_strength) * self.topic_vector[i] +\n",
    "                self.model.influence_strength * esg_weights[i] * avg_neighbor_topics[i]\n",
    "                for i in range(BEST_TOPIC_COUNT)\n",
    "            ]\n",
    "\n",
    "    def advance(self):\n",
    "        self.sentiment = max(1.0, min(5.0, self.sentiment))\n",
    "        total = sum(self.topic_vector)\n",
    "        if total > 0: self.topic_vector = [p / total for p in self.topic_vector]\n",
    "\n",
    "class ESGReviewModel(Model):\n",
    "    def __init__(self, N=500, influence_strength=0.1, confidence_threshold=1.0, intervention_rate=0.1, baseline_df=None, seed=None):\n",
    "        super().__init__()\n",
    "        self.num_agents = N\n",
    "        self.influence_strength = influence_strength\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.intervention_rate = intervention_rate\n",
    "        self.G = nx.barabasi_albert_graph(n=N, m=2, seed=seed)\n",
    "        self.grid = NetworkGrid(self.G)\n",
    "        self.schedule = SimultaneousActivation(self)\n",
    "        self.intervention_steps = []\n",
    "        self.baseline_df = baseline_df\n",
    "        self.seed = seed\n",
    "\n",
    "        for i, node in enumerate(self.G.nodes()):\n",
    "            total = sum(topic_vectors[i])\n",
    "            normalized_topics = [p / total for p in topic_vectors[i]] if total > 0 else [1/BEST_TOPIC_COUNT]*BEST_TOPIC_COUNT\n",
    "            agent = ReviewerAgent(i, self, sentiment_values[i], normalized_topics)\n",
    "            self.schedule.add(agent)\n",
    "            self.grid.place_agent(agent, node)\n",
    "\n",
    "        model_reporters = {\n",
    "            \"AverageSentiment\": lambda m: np.mean([a.sentiment for a in m.schedule.agents]),\n",
    "            \"TopicDiversity\": lambda m: np.mean([-sum(p * np.log(p + 1e-10) for p in a.topic_vector) / np.log(BEST_TOPIC_COUNT) for a in m.schedule.agents]) if m.schedule.agents else 0.0\n",
    "        }\n",
    "        for i in range(BEST_TOPIC_COUNT):\n",
    "            model_reporters[f\"Topic_{i}_Adoption\"] = lambda m, idx=i: sum(1 for a in m.schedule.agents if a.topic_vector[idx] > 0.25) / m.num_agents\n",
    "\n",
    "        self.datacollector = DataCollector(model_reporters=model_reporters)\n",
    "        self.degree_centrality = nx.degree_centrality(self.G)\n",
    "        self.betweenness_centrality = nx.betweenness_centrality(self.G)\n",
    "\n",
    "    def step(self):\n",
    "        if random.random() < self.intervention_rate:\n",
    "            self.intervention_steps.append(self.schedule.steps)\n",
    "            agents_to_intervene = random.sample(list(self.schedule.agents), int(self.num_agents * 0.1))\n",
    "            for agent in agents_to_intervene:\n",
    "                agent.sentiment = min(5.0, agent.sentiment + 0.5)\n",
    "                if BEST_TOPIC_COUNT > 5:\n",
    "                    agent.topic_vector[4] += 0.15\n",
    "                    agent.topic_vector[5] += 0.15\n",
    "                agent.intervened = True\n",
    "                total = sum(agent.topic_vector)\n",
    "                if total > 0:\n",
    "                    agent.topic_vector = [p / total for p in agent.topic_vector]\n",
    "\n",
    "        self.datacollector.collect(self)\n",
    "        self.schedule.step()\n",
    "\n",
    "    def get_intervention_impact(self):\n",
    "        if not self.intervention_steps or self.baseline_df is None:\n",
    "            return {f\"CIE_Topic_{i}\": 0.0 for i in range(BEST_TOPIC_COUNT)}, 0.0\n",
    "        current_df = self.datacollector.get_model_vars_dataframe()\n",
    "        total_steps = len(current_df)\n",
    "        \n",
    "        cie_adoption = {f\"CIE_Topic_{i}\": np.trapz(\n",
    "            [current_df[f\"Topic_{i}_Adoption\"][max(0, s):].mean() - self.baseline_df[f\"Topic_{i}_Adoption\"][max(0, s):].mean() \n",
    "             for s in self.intervention_steps], dx=1) / total_steps for i in range(BEST_TOPIC_COUNT)}\n",
    "        cie_sentiment = np.trapz(\n",
    "            [current_df[\"AverageSentiment\"][max(0, s):].mean() - self.baseline_df[\"AverageSentiment\"][max(0, s):].mean() \n",
    "             for s in self.intervention_steps], dx=1) / total_steps\n",
    "\n",
    "        return cie_adoption, cie_sentiment\n",
    "\n",
    "# ===== Run Simulation & Generate Plots =====\n",
    "if __name__ == \"__main__\":\n",
    "    # --- 1. Run Baseline Simulation Globally ---\n",
    "    print(\"--- Running global baseline simulation ---\")\n",
    "    baseline_runs = []\n",
    "    for i in range(10):\n",
    "        baseline_model = ESGReviewModel(N=500, influence_strength=0.1, confidence_threshold=1.0, intervention_rate=0.0, seed=i)\n",
    "        for _ in range(100):\n",
    "            baseline_model.step()\n",
    "        baseline_runs.append(baseline_model.datacollector.get_model_vars_dataframe())\n",
    "    baseline_df = pd.concat(baseline_runs).groupby(level=0).mean()\n",
    "\n",
    "    # --- 2. Run Main Simulations ---\n",
    "    scenarios_config = [\n",
    "        {\"name\": \"Scenario 1 (Baseline)\", \"params\": {\"N\": 500, \"influence_strength\": 0.15, \"confidence_threshold\": 1.0, \"intervention_rate\": 0.1}},\n",
    "        {\"name\": \"Scenario 2 (Stagnation)\", \"params\": {\"N\": 500, \"influence_strength\": 0.05, \"confidence_threshold\": 0.5, \"intervention_rate\": 0.0}},\n",
    "        {\"name\": \"Scenario 3 (Acceleration)\", \"params\": {\"N\": 500, \"influence_strength\": 0.2, \"confidence_threshold\": 1.5, \"intervention_rate\": 0.2}}\n",
    "    ]\n",
    "\n",
    "    scenario_results = []\n",
    "    print(\"--- Running all simulation scenarios ---\")\n",
    "    for scenario in scenarios_config:\n",
    "        print(f\"Running {scenario['name']}...\")\n",
    "        run_results = []\n",
    "        for i in range(10):\n",
    "            model = ESGReviewModel(**scenario['params'], baseline_df=baseline_df, seed=i)\n",
    "            for _ in range(100):\n",
    "                model.step()\n",
    "            results_df = model.datacollector.get_model_vars_dataframe()\n",
    "            cie_adoption, cie_sentiment = model.get_intervention_impact()\n",
    "            for key, value in cie_adoption.items():\n",
    "                results_df[key] = value\n",
    "            results_df[\"CIESentiment\"] = cie_sentiment\n",
    "            run_results.append(results_df)\n",
    "        avg_results_df = pd.concat(run_results).groupby(level=0).mean()\n",
    "        scenario_results.append({\"name\": scenario['name'], \"data\": avg_results_df})\n",
    "        \n",
    "        output_file = os.path.join(input_dir, f\"abm_results_{scenario['name'].split(' ')[1]}.csv\")\n",
    "        avg_results_df.to_csv(output_file, index=True)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    # --- 3. Generate Plots ---\n",
    "    print(\"\\n--- Generating plots ---\")\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12, 'axes.labelsize': 14, 'axes.titlesize': 16,\n",
    "        'legend.fontsize': 11, 'xtick.labelsize': 12, 'ytick.labelsize': 12,\n",
    "        'axes.linewidth': 1.5, 'lines.linewidth': 2.0, 'figure.figsize': (11, 7),\n",
    "        'font.family': 'serif',\n",
    "    })\n",
    "    \n",
    "    distinct_colors = [\n",
    "        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "        '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'\n",
    "    ]\n",
    "\n",
    "    # === Individual Scenario Plots (Adoption and Sentiment Trends) ===\n",
    "    for result in scenario_results:\n",
    "        name, df = result['name'], result['data']\n",
    "        fig, ax1 = plt.subplots(figsize=(11, 7))\n",
    "        \n",
    "        adoption_cols = [col for col in df.columns if 'Adoption' in col]\n",
    "        ax1.set_xlabel('Simulation Step')\n",
    "        ax1.set_ylabel('Topic Adoption (Proportion)', color='k')\n",
    "        for i, col in enumerate(adoption_cols):\n",
    "            ax1.plot(df.index, df[col], label=col.replace('_', ' ').replace('Topic ', 'T'), color=distinct_colors[i % len(distinct_colors)])\n",
    "        ax1.tick_params(axis='y', labelcolor='k')\n",
    "        ax1.set_ylim(0, 1.05)\n",
    "        ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        ax1_twin = ax1.twinx()\n",
    "        ax1_twin.set_ylabel('Average Sentiment (1-5 Scale)', color='crimson')\n",
    "        ax1_twin.plot(df.index, df['AverageSentiment'], label='Avg Sentiment', color='crimson', linestyle='--', linewidth=2.5)\n",
    "        ax1_twin.tick_params(axis='y', labelcolor='crimson')\n",
    "        ax1_twin.set_ylim(4, 5)\n",
    "\n",
    "        plt.title(f'{name}: Adoption and Sentiment Trends')\n",
    "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax1_twin.get_legend_handles_labels()\n",
    "        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper center', bbox_to_anchor=(0.5, -0.15), frameon=True, ncol=5)\n",
    "        fig.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "\n",
    "        plt.savefig(os.path.join(input_dir, f\"{name.replace(' ', '_')}_trends.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # === Network Centrality Plot ===\n",
    "    model = ESGReviewModel(**scenarios_config[0]['params'], baseline_df=baseline_df, seed=0)  # Use seed 0 for consistency\n",
    "    centrality_df = pd.DataFrame({\n",
    "        'DegreeCentrality': list(model.degree_centrality.values()),\n",
    "        'BetweennessCentrality': list(model.betweenness_centrality.values()),\n",
    "        'AdoptionInfluence': [sum(a.topic_vector[i] > 0.25 for i in range(BEST_TOPIC_COUNT)) / BEST_TOPIC_COUNT for a in model.schedule.agents]\n",
    "    })\n",
    "    centrality_df_filtered = centrality_df[centrality_df['AdoptionInfluence'] > 0.0]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(data=centrality_df_filtered, x='DegreeCentrality', y='BetweennessCentrality', size='AdoptionInfluence', \n",
    "                    hue='AdoptionInfluence', palette='viridis', alpha=0.8)\n",
    "    plt.title('Network Centrality vs. Adoption Influence')\n",
    "    plt.xlabel('Degree Centrality')\n",
    "    plt.ylabel('Betweenness Centrality')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(os.path.join(input_dir, \"network_centrality.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # === Evolution of Topic Diversity Across Scenarios Plot ===\n",
    "    fig, ax = plt.subplots(figsize=(11, 7))\n",
    "    for result in scenario_results:\n",
    "        name, df = result['name'], result['data']\n",
    "        ax.plot(df.index, df['TopicDiversity'], label=name, color=distinct_colors[scenario_results.index(result) % len(distinct_colors)])\n",
    "    \n",
    "    ax.set_xlabel('Simulation Step')\n",
    "    ax.set_ylabel('Topic Diversity (Normalized Entropy)')\n",
    "    ax.set_title('Evolution of Topic Diversity Across Scenarios')\n",
    "    ax.set_ylim(0.5, 0.85)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(input_dir, \"topic_diversity_evolution.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Generated all plots and results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e95eb8-efe6-4ae1-b1ac-09d1a09899f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede25fa-86ab-4b78-80ee-b18f170e3109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
